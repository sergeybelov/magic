{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scipy.sparse import hstack\n",
    "import datetime as dt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 35, 40\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "from plotly import __version__\n",
    "from plotly import graph_objs as go\n",
    "from plotly.graph_objs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Читаем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_pickle('MG_Sales_customer.pickle',compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (242572, 70925)\n",
      "Prepare finished\n"
     ]
    }
   ],
   "source": [
    "#---------------------------\n",
    "#выбираем покупателей для дальнейшего анализа\n",
    "sales_sum=df.groupby('Покупатель')['Количество'].sum()\n",
    "#выкидываем со слишком большими продажами (сводные карты) и тех кто купил один раз\n",
    "sales_sum.drop(sales_sum[(sales_sum>133)|(sales_sum==1)].index, inplace=True)\n",
    "customers_name=list(sales_sum.index)\n",
    "del sales_sum\n",
    "\n",
    "#делаем выборку\n",
    "select=df.loc[(df['Покупатель'].isin(customers_name))&(df['Дата']>=(dt.datetime(2014,1,1))),['Покупатель','ПокупательПол','ПокупательДатаРождения','ВидИзделия','ПодвидИзделия','СтильДизайна','ВидДизайна','ОсновнойКамень','ГруппаТовара','Коллекция','ЦветМеталла','ТоварСреднийВес','Размер','Вес','Количество']]\n",
    "del customers_name\n",
    "del df\n",
    "\n",
    "#Подготовка датасета\n",
    "#ЦветМеталла=list(map(lambda xx: xx,list(select['ЦветМеталла'].unique())))\n",
    "def codeMetall(_str):    \n",
    "    for str_split in _str.lower().split():\n",
    "        if str_split=='серебро': return 0\n",
    "        if str_split=='золото': return 10\n",
    "        if str_split=='зол.': return 11\n",
    "        if str_split=='платина': return 20\n",
    "        if str_split=='сплав': return -10\n",
    "    return -20\n",
    "\n",
    "select['ПокупательПолКод']=select['ПокупательПол'].map(lambda xx: {'Ж':0, 'М':1, '<Неопределено>':None}[xx])\n",
    "select['ЦветМеталлаКод']=select['ЦветМеталла'].map(lambda xx: codeMetall(xx))\n",
    "select['ПокупательПолКод'].fillna(select['ПокупательПолКод'].median(),inplace=True)\n",
    "select['ПокупательГодРождения']=select['ПокупательДатаРождения'].dt.year\n",
    "select['ПокупательГодРождения']=select['ПокупательГодРождения'].map(lambda xx: None if xx<1917 else xx)\n",
    "select['ПокупательГодРождения']=select['ПокупательГодРождения'].map(lambda xx: None if xx>2010 else xx)\n",
    "select['ПокупательГодРождения'].fillna(select['ПокупательГодРождения'].median(),inplace=True)\n",
    "select.drop(['ПокупательДатаРождения','ПокупательПол','ЦветМеталла','ПокупательПолКод','ПокупательГодРождения'],  axis=1, inplace=True)\n",
    "#выборка колонок\n",
    "numerical_columns = [c for c in select.columns if select[c].dtype.name != 'object']\n",
    "categorial_columns = [c for c in select.columns if select[c].dtype.name == 'object']\n",
    "\n",
    "\n",
    "#Dummy-кодирование и шкалируем\n",
    "lb_style = LabelBinarizer(sparse_output=True)\n",
    "concList=[]\n",
    "for col in categorial_columns:\n",
    "    concList.append(lb_style.fit_transform(select[col]))    \n",
    "concList.append(StandardScaler().fit_transform(select[numerical_columns]))#добавляем шклированные значения числовых переменных\n",
    "X=hstack(concList)\n",
    "\n",
    "del concList\n",
    "print('shape ',X.shape)\n",
    "print('Prepare finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134\n",
      "reduced\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "svd = TruncatedSVD(n_components=150, n_iter=5)\n",
    "svd_representation = svd.fit_transform(X)\n",
    "var1=np.cumsum(np.round(svd.explained_variance_ratio_, decimals=5)*100)\n",
    "#plt.plot(var1[-50:])\n",
    "\n",
    "#расчитываем оптимальное количество компонент\n",
    "#более 90% дисперсии и шаг приращения каждой следующей компоненты <10^-4\n",
    "optimal_n=np.intersect1d(np.argwhere(var1>90.),np.argwhere(svd.explained_variance_ratio_<=10**-4))[0]\n",
    "print(optimal_n)#171\n",
    "\n",
    "if optimal_n==None:\n",
    "    raise 'Not enough n_components!'\n",
    "\n",
    "svd = TruncatedSVD(n_components=optimal_n, n_iter=7)\n",
    "svd_representation = svd.fit_transform(X)\n",
    "print('reduced')\n",
    "del var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4a7859adaa7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mdel\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "del X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MiniBatchKMeans Elapsed time to cluster: 17.4187 s\n"
     ]
    }
   ],
   "source": [
    "n_clusters=7\n",
    "\n",
    "\n",
    "hdb_t1 = time.time()\n",
    "#hdb = MiniBatchKMeans(n_clusters=n_clusters,max_iter=150,max_no_improvement=25,n_init=15,tol=.01,batch_size=15,random_state=17).fit(svd_representation)\n",
    "#hdb = MiniBatchKMeans(n_clusters=n_clusters,max_iter=150,max_no_improvement=25,tol=.01,batch_size=200,n_init=15,random_state=17).fit(svd_representation)\n",
    "#hdb = MiniBatchKMeans(n_clusters=n_clusters,max_iter=150,tol=.01,max_no_improvement=25,batch_size=15,n_init=15,random_state=17).fit(X)\n",
    "hdb = MiniBatchKMeans(n_clusters=n_clusters,max_iter=250,max_no_improvement=25,n_init=15,batch_size=10,random_state=17).fit(svd_representation)\n",
    "\n",
    "\n",
    "hdb_elapsed_time = time.time() - hdb_t1\n",
    "print('MiniBatchKMeans Elapsed time to cluster: %.4f s' % (hdb_elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time to cluster:    2.6 m\n",
      "For n_clusters = 7 The average silhouette_score is : 0.189395857898\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#svd_representation=X.copy()\n",
    "\n",
    "ss = ShuffleSplit(n_splits=2, train_size=int(svd_representation.shape[0]*.2))\n",
    "subs= ss.split(svd_representation)#,hdb.labels_\n",
    "\n",
    "for index in subs:\n",
    "    X=svd_representation[index[0]]#.tocsr()\n",
    "    cluster_labels=hdb.labels_[index[0]]\n",
    "                        \n",
    "    hdb_t1 = time.time()\n",
    "    \n",
    "    fig, (ax1) = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(12, 8)\n",
    "    \n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 \n",
    "    ax1.set_xlim([-.6, .6])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, X.shape[0] + (n_clusters + 1) * 12])\n",
    "    \n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print('Elapsed time to cluster: %6.1f m' % ((time.time()-hdb_t1)/60))\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "                  \"The average silhouette_score is :\", silhouette_avg)\n",
    "    \n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "    \n",
    "    y_lower = 12\n",
    "    for i in range(n_clusters):\n",
    "                # Aggregate the silhouette scores for samples belonging to\n",
    "                # cluster i, and sort them\n",
    "                ith_cluster_silhouette_values = \\\n",
    "                    sample_silhouette_values[cluster_labels == i]\n",
    "    \n",
    "                ith_cluster_silhouette_values.sort()\n",
    "    \n",
    "                size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "                y_upper = y_lower + size_cluster_i\n",
    "    \n",
    "                color = cm.spectral(float(i) / n_clusters)\n",
    "                ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                                  0, ith_cluster_silhouette_values,\n",
    "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
    "    \n",
    "                # Label the silhouette plots with their cluster numbers at the middle\n",
    "                ax1.text(-0.5, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "    \n",
    "                # Compute the new y_lower for next plot\n",
    "                y_lower = y_upper + 12  # 10 for the 0 samples\n",
    "    \n",
    "    set_xlabel=\"The avg silhouette coefficient values = \"+str(round(silhouette_avg,3))\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(set_xlabel)\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "    \n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "    \n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks(list(np.arange(-.6,1,.2)))\n",
    "    \n",
    "    plt.suptitle((\"Silhouette analysis for MiniBatchKMeans clustering on sample data \"\n",
    "                          \"with n_clusters = %d\" % n_clusters),\n",
    "                         fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    del X\n",
    "    del cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "select['ЦветМеталлаКод']=select['ЦветМеталлаКод'].map(lambda xx: {0: 'серебро', 10: 'золото', 11: 'золото', 20: 'платина',-10: 'сплав', -20: 'прочее'}[xx])\n",
    "#select['ПокупательПолКод']=select['ПокупательПолКод'].map(lambda xx: {0: 'Ж', 1: 'М'}[xx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comma=','\n",
    "\n",
    "#Выводим данные по кластерам в сводную таблицу\n",
    "clusters_data=pd.DataFrame(columns=select.columns)\n",
    "for cl in range(hdb.cluster_centers_.shape[0]):\n",
    "    sel=select.loc[hdb.labels_==cl].describe(include='all')\n",
    "    clust_info=sel.loc[['top','mean']]\n",
    "    \n",
    "    cat_lbls=list(clust_info.loc['top',pd.notnull(clust_info.loc['top'])].index)#категориальные переменные\n",
    "    #Рассчитываем три максимальных значения\n",
    "    for col in cat_lbls:    \n",
    "        str_vals=list(select.loc[hdb.labels_==cl].groupby(col)['Покупатель'].count().sort_values(ascending=False).head(3).index)\n",
    "        #clust_info.loc['top',col]=str_vals.translate(trantab)\n",
    "        clust_info.loc['top',col]=comma.join(str_vals)\n",
    "    \n",
    "    clusters_data.loc[cl+1]=pd.concat([clust_info.fillna('').sum(axis=0),clust_info.fillna(0).sum(axis=0)])\n",
    "    #clusters_data.loc[cl+1,'Количество']=sel.loc['count','Покупатель']\n",
    "    clusters_data.loc[cl+1,'УникальныхПокупателей']=sel.loc['unique','Покупатель']\n",
    "    clusters_data.loc[cl+1,'ЧастотаПокупок']=sel.loc['freq','Покупатель']\n",
    "clusters_data.drop('Количество',axis=1,inplace=True)\n",
    "clusters_data.sort_values('УникальныхПокупателей',inplace=True, ascending=False)\n",
    "\n",
    "clusters_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select.loc[hdb_labels==0].groupby('ВидИзделия')['Количество'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(var1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
